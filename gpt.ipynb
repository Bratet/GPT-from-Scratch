{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train BPE tokenizer\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "trainer = trainers.BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer.train(files=[\"input.txt\"], trainer=trainer)\n",
    "tokenizer.decoder = decoders.WordPiece()\n",
    "\n",
    "# Tokenize the text using BPE tokenizer\n",
    "tokenized_text = tokenizer.encode(text).tokens\n",
    "\n",
    "# Create a token-based vocabulary\n",
    "token_counts = Counter(tokenized_text)\n",
    "tokens = sorted(token_counts.keys())\n",
    "token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
    "idx_to_token = {idx: token for token, idx in token_to_idx.items()}\n",
    "\n",
    "# Convert the tokenized text into numerical data\n",
    "data = [token_to_idx[token] for token in tokenized_text if token in token_to_idx]\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "BLOCK_SIZE = 128\n",
    "\n",
    "# Create batches\n",
    "num_batches = len(data) // (BATCH_SIZE * BLOCK_SIZE)\n",
    "data = data[:num_batches * BATCH_SIZE * BLOCK_SIZE]\n",
    "data_batches = torch.tensor(data).view(BATCH_SIZE, -1)\n",
    "\n",
    "# train/val split\n",
    "train_batches = int(0.9 * num_batches)\n",
    "train_data = data_batches[:, :train_batches * BLOCK_SIZE]\n",
    "val_data = data_batches[:, train_batches * BLOCK_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "src_token_size = len(tokens)\n",
    "tgt_token_size = len(tokens)\n",
    "d_model = 512\n",
    "h = 8\n",
    "d_ff = 2048\n",
    "num_layers = 6\n",
    "dropout = 0.2\n",
    "max_len = len(tokens)\n",
    "\n",
    "# Create the model\n",
    "model = Transformer(src_token_size, tgt_token_size, d_model, h, d_ff, num_layers, dropout, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 9.4273, Val Loss: 9.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 8.3923, Val Loss: 8.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 7.7498, Val Loss: 7.4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 7.1094, Val Loss: 6.8045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 6.5694, Val Loss: 6.4051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 6.2423, Val Loss: 6.1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 5.9787, Val Loss: 5.9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 5.7366, Val Loss: 5.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Train Loss: 5.5345, Val Loss: 5.5903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Train Loss: 5.3634, Val Loss: 5.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Train Loss: 5.2234, Val Loss: 5.4232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Train Loss: 5.1075, Val Loss: 5.3758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Train Loss: 5.0062, Val Loss: 5.3335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Train Loss: 4.9123, Val Loss: 5.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Train Loss: 4.8303, Val Loss: 5.2886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Train Loss: 4.7538, Val Loss: 5.2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Train Loss: 4.6814, Val Loss: 5.2884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Train Loss: 4.6090, Val Loss: 5.2736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Train Loss: 4.5420, Val Loss: 5.2789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 4.4830, Val Loss: 5.2854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "WARMUP_EPOCHS = 10\n",
    "INITIAL_LR = 1e-6  \n",
    "\n",
    "# Warmup function\n",
    "def warmup_lr_scheduler(epoch, optimizer):\n",
    "    if epoch < WARMUP_EPOCHS:\n",
    "        lr = INITIAL_LR + (1e-4 - INITIAL_LR) * (epoch / WARMUP_EPOCHS)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    warmup_lr_scheduler(epoch, optimizer)\n",
    "    \n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    # Compute the number of training batches\n",
    "    train_batches = (train_data.size(1) - BLOCK_SIZE + BLOCK_SIZE - 1) // BLOCK_SIZE\n",
    "    \n",
    "    # Training\n",
    "    train_loop = tqdm(range(0, train_data.size(1) - BLOCK_SIZE, BLOCK_SIZE), total=train_batches, leave=False)\n",
    "    for i in train_loop:\n",
    "        inputs = train_data[:, i:i+BLOCK_SIZE].to(device)\n",
    "        targets = train_data[:, i+1:i+1+BLOCK_SIZE].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs, inputs)\n",
    "        loss = criterion(outputs.view(-1, tgt_token_size), targets.view(-1))\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loop.set_description(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "        train_loop.set_postfix(train_loss=total_train_loss/(i//BLOCK_SIZE + 1))\n",
    "    \n",
    "    # Compute the number of validation batches\n",
    "    val_batches = (val_data.size(1) - BLOCK_SIZE + BLOCK_SIZE - 1) // BLOCK_SIZE\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_loop = tqdm(range(0, val_data.size(1) - BLOCK_SIZE, BLOCK_SIZE), total=val_batches, leave=False)\n",
    "    with torch.no_grad():\n",
    "        for i in val_loop:\n",
    "            inputs = val_data[:, i:i+BLOCK_SIZE].to(device)\n",
    "            targets = val_data[:, i+1:i+1+BLOCK_SIZE].to(device)\n",
    "            \n",
    "            outputs = model(inputs, inputs)\n",
    "            loss = criterion(outputs.view(-1, tgt_token_size), targets.view(-1))\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            val_loop.set_description(f\"Epoch {epoch + 1}/{NUM_EPOCHS} (Validation)\")\n",
    "            val_loop.set_postfix(val_loss=total_val_loss/(i//BLOCK_SIZE + 1))\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {total_train_loss/train_batches:.4f}, Val Loss: {total_val_loss/val_batches:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are accounted poor citizens by head o Unwieldy passes loins true great all crimes in every deliver in all declining in dark : intercepts in all disorder men in all in all in all alarms of King all Rutland being string in yours pieces short all refuse in all Gave all congealed in in\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "start_text = \"We are accounted poor citizens\"\n",
    "start_tokens = tokenizer.encode(start_text).tokens\n",
    "start_tokens = [token_to_idx[token] for token in start_tokens if token in token_to_idx]\n",
    "start_tokens = torch.tensor(start_tokens).unsqueeze(0)\n",
    "\n",
    "generated_text_indices = model.generate(start_tokens.to(device), max_new_tokens=50)\n",
    "\n",
    "# Convert the generated indices back to tokens\n",
    "generated_tokens = [idx_to_token[idx] for idx in generated_text_indices[0].cpu().numpy()]\n",
    "\n",
    "# Convert the tokens into their respective IDs\n",
    "generated_token_ids = [tokenizer.token_to_id(token) for token in generated_tokens]\n",
    "\n",
    "# Decode the sequence of IDs\n",
    "generated_text = tokenizer.decode(generated_token_ids)\n",
    "\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
